{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2289c00-c78f-4b01-a64e-0a43ef5687b6",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273e808-a840-4837-9f2b-12f5b0bffc44",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "$x_i$ = input layer<br>\n",
    "$w_i$ = weights<br>\n",
    "$b$ = bias<br>\n",
    "$z$ = hidden layer<br>\n",
    "$f(z)$ = activation<br>\n",
    "\n",
    "$z = \\sum\\limits_{i=1}^{n}x_iw_i + b$<br>\n",
    "Given Sigmoid as activation function: $f(H) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "**Remark**<br>\n",
    "$w_i$ for b is 1<br>\n",
    "Which activation function to choose depends on the prediction output: number/category<br>\n",
    "If numerical output, MSE loss function will be used, reLU, linear(Identity) activation will be used.<br>\n",
    "If categorical output, cross entropy loss function will be used, sigmoid, tanh, softmax (non linear) activation function will be used.\n",
    "\n",
    "\n",
    "\n",
    "### Back propagation\n",
    "incrementally tweaking the networkâ€™s weights until the lowest possible cost value is obtained.\n",
    "\n",
    "### Partial derivative for $w_i$: $\\frac{\\partial C}{\\partial w_i} = \\frac{\\partial C}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial z} * \\frac{\\partial z}{\\partial w_i}$\n",
    "\n",
    "1. $\\frac{\\partial C}{\\partial \\hat{y}} = \\frac{\\partial}{\\partial \\hat{y}}\\frac{1}{n}\\sum\\limits_{i=1}^{n}(y_i-\\hat{y_i})^2 = \\frac{2}{n}\\sum\\limits_{1=1}^{n}(y_i-\\hat{y_i})$\n",
    "\n",
    "2. Given $\\sigma$ = Sigmoid function (different activation function has different derivative below)\n",
    "\n",
    "3. $\\frac{\\partial \\hat{y}}{\\partial z} = \\frac{\\partial}{\\partial z}\\sigma(z) = \\sigma(z) * (1-\\sigma(z)) $\n",
    "\n",
    "4. $\\frac{\\partial z}{\\partial w_i} = \\frac{\\partial}{\\partial w_i}\\sum\\limits_{i=1}^{n}x_iw_i+b = x_i$\n",
    "\n",
    "### $\\frac{\\partial C}{\\partial w_i} = \\frac{2}{n} * \\sum\\limits_{i=1}^{n}(y_i - \\hat{y_i}) * \\sigma(z) * (1-\\sigma(z)) * x_i$\n",
    "\n",
    "### Partial derivative for $b$\n",
    "### $\\frac{\\partial C}{\\partial b} = \\frac{2}{n} * \\sum\\limits_{i=1}^{n}(y_i-\\hat{y_i}) * \\sigma(z) * (1-\\sigma(z))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c2a1f-a631-4637-930e-f09d6dc7b484",
   "metadata": {},
   "source": [
    "# Cost Function\n",
    "##### MSE = $\\frac{1}{n}\\sum\\limits_{i=1}^{n}(y_i - \\hat{y_i})^2$\n",
    "\n",
    "##### Cross entropy = $\\frac{1}{n}\\sum\\limits_{i=1}^{n} [y * \\log(\\hat{y}) + (1-y) * \\log(1-\\hat{y})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597659c-49a8-45d6-a98e-907cddcb5f49",
   "metadata": {},
   "source": [
    "### learning algorithm\n",
    "1. Start with values (often random) for the network parameters (wij weights and bj biases).\n",
    "2. Take a set of examples of input data and pass them through the network to obtain their prediction.\n",
    "3. Compare these predictions obtained with the values of expected labels and calculate the loss with them.\n",
    "4. Perform the backpropagation in order to propagate this loss to each and every one of the parameters that make up the model of the neural network.\n",
    "5. Use this propagated information to update the parameters of the neural network with the gradient descent in a way that the total loss is reduced and a better model is obtained.\n",
    "6. Continue iterating in the previous steps until we consider that we have a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980ee795-30a8-4d29-b4ce-3ec3a8a00d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn.datasets import make_moons\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fedae-62a8-4593-93fa-605c2669cf81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca83a305-904a-4ae3-b316-8e35317f14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    pass\n",
    "\n",
    "def softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    sm = ez / np.sum(ez)\n",
    "    return sm\n",
    "\n",
    "def relu(z):\n",
    "    return max(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea98e812-3bba-4511-b7fc-4b48076cd119",
   "metadata": {},
   "source": [
    "### Cost Function: cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a627f-03ce-4de9-b4a9-c85a232dfab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_Entropy(theta, X, y):\n",
    "    m = y.shape[0]\n",
    "    theta = theta[:, np.newaxis] #trick to make numpy minimize work\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    J = (1/m) * (-y.T.dot(np.log(h)) - (1-y).T.dot(np.log(1-h)))\n",
    "\n",
    "    grad = (1/m) * (h - y).T.dot(X)\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5c7bf-7b86-436b-bef3-d2ca79b2fdeb",
   "metadata": {},
   "source": [
    "### Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bfaeef-5cc5-4fbe-9794-db2625cdefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense(a_in, W, b):  \n",
    "    z = a_in @ W + b\n",
    "    a_out = sigmoid(z)\n",
    "    return a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248e0937-cd3b-4ad7-adf0-42dc7b2d222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequential(X, W1, b1, W2, b2, W3, b3):\n",
    "    a1 = Dense(X, W1, b1)\n",
    "    a2 = Dense(a1, W2, b2)\n",
    "    a3 = Dense(a2, W3, b3)\n",
    "    return a3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b81e8-2bdd-4f81-a0dc-a1d74d14aea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569b0a43-12e6-42b2-a7b6-b3889a09ce14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Predict(X, W1, b1, W2, b2, W3, b3):    \n",
    "    output = Sequential(X, W1, b1, W2, b2, W3, b3)\n",
    "    y_hat = np.zeros_like(output)\n",
    "    for i in range(len(output)):\n",
    "        if output[i] > 0.5:\n",
    "            y_hat[i] = 1\n",
    "        else:\n",
    "            y_hat[i] = 0\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a961b4-1e92-44f3-a602-f931465aac73",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "031c4161-5156-488d-86c6-95941c8e54b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0     8450            7            5          856         2         1   \n",
       "1     9600            6            8         1262         2         0   \n",
       "2    11250            7            5          920         2         1   \n",
       "3     9550            7            5          756         1         0   \n",
       "4    14260            8            5         1145         2         1   \n",
       "\n",
       "   BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0             3             8           0         548                 1  \n",
       "1             3             6           1         460                 1  \n",
       "2             3             6           1         608                 1  \n",
       "3             3             7           1         642                 0  \n",
       "4             4             9           1         836                 1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('housepricedata.csv')\n",
    "dataset = df.values\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:, -1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07be50e1-0b4d-44dc-9908-7ad90944b969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
