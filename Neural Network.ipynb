{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248cbd58-4e56-45c1-b948-8fe1ad66f048",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "The most basic form of a feed forward neural network. It is designed as a decision function for receiving inputs to produce a binary output.\n",
    "\n",
    "### alternative \n",
    "sigmoid neuron <br>\n",
    "hyperbolic tangent function\n",
    "\n",
    "Each node in the hidden layer represents a function, such as a sigmoid function, but with its own unique weights/hyperparameters. <br>\n",
    "This means that each input variable, in effect, is exposed to five different functions. <br>\n",
    "Simultaneously, the hidden layer nodes are exposed to all four features.\n",
    "\n",
    "The final output layer for this model consists of two discrete outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273e808-a840-4837-9f2b-12f5b0bffc44",
   "metadata": {},
   "source": [
    "### back-propagation\n",
    "incrementally tweaking the networkâ€™s weights until the lowest possible cost value is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597659c-49a8-45d6-a98e-907cddcb5f49",
   "metadata": {},
   "source": [
    "### learning algorithm\n",
    "1. Start with values (often random) for the network parameters (wij weights and bj biases).\n",
    "2. Take a set of examples of input data and pass them through the network to obtain their prediction.\n",
    "3. Compare these predictions obtained with the values of expected labels and calculate the loss with them.\n",
    "4. Perform the backpropagation in order to propagate this loss to each and every one of the parameters that make up the model of the neural network.\n",
    "5. Use this propagated information to update the parameters of the neural network with the gradient descent in a way that the total loss is reduced and a better model is obtained.\n",
    "6. Continue iterating in the previous steps until we consider that we have a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62207d73-5630-4240-a351-7fb5e1697f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fedae-62a8-4593-93fa-605c2669cf81",
   "metadata": {},
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802571c2-d8b6-4331-81e3-1c5043dba59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(z):\n",
    "    pass z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a6a40-a29c-4512-a78d-e759be4d391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112c0481-298d-410f-8905-3bea371a28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    pass np.tanh(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c2e0a8-71f7-4dbe-a216-c9e32eba943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513a86b7-fbe3-4b15-a912-a95409d3efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    if z <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0748c7-4fd9-4c50-9668-b356ada8c826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
